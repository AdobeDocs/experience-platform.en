---
title: Model Cards For AI Model Transparency In Adobe Experience Platform
description: Learn about model cards in Adobe Experience Platform.
hide: true
hidefromtoc: true
exl-id: 74a8ef82-cff9-4a7e-95c8-f915eb664eda
---
# Model cards for AI model transparency in Adobe Experience Platform

Model cards are the standard formats by which AI model transparency is communicated. Model cards are public and are intended to improve both existing and prospective customer understanding of the AI models that Adobe uses. Model cards are generally static. However, there are several aspects of AI models that can change over time, including lineage, bias, and other transparency attributes.

Read this document to learn about model cards in Adobe Experience Platform.

## Model card sections {#model-card-sections}

Read the following for a guide on the different sections of a model card, including information the questions they address.

### Model overview {#model-overview}

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What is the name of the model? | The official name and version of the AI model | **CustomerAI Propensity Scoring Model v2.0** <br>CustomerAI is an AI-powered model designed to generate propensity scores for users based on their past behaviors and interactions with a business. It helps predict the likelihood of a customer taking specific actions, such as making a purchase, engaging with content, or churning. This model is deployed within Adobe Experience Platform and integrates with various marketing and customer analytics workflows.</br> |
| What is the purpose of the model? | A brief description of what the model is designed to do. | The model is designed to provide marketers and customer engagement teams with actionable insights by predicting the probability that a customer will perform a given action, such as making a purchase, signing up for a subscription, or engaging with an email campaign. The outputs allow businesses to optimize audience segmentation and personalize customer interactions based on predicted behaviors. |
| What type of model is it? | The type of the model, such as classification, regression, generative, etc. | This is a s**upervised learning classification model** that predicts the probability of an event occurring (e.g., purchase, churn, engagement) given historical customer data. It is trained using gradient boosting decision trees (GBDT) with logistic regression to model propensity scores. |
| Who are the intended users? | The internal and external user groups that the model is intended for. | The primary users of this model are marketing professionals, data analysts, and customer engagement teams who leverage Adobe Experience Platform to drive data-driven marketing strategies. |
| How does this model integrate with Adobe Experience Platform? | The integration details and APIs used, as well as how they fit into the workflows. | CustomerAI integrates directly into **Adobe Experience Platform's AI services**, allowing users to access model outputs through pre-built APIs and dashboards. The propensity scores generated by the model can be used within **Adobe Journey Optimizer**, **and Adobe Real-Time CDP**, to refine audience segmentation and tailor marketing strategies. |

{style="table-layout:auto"}

+++

### Intended use {#intended-use}

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What are the primary use cases? | The scenarios where the model is expected to be used. | This model is primarily used for **customer segmentation, targeted marketing, and churn prediction**. Businesses leverage this model to **predict customer purchase intent, optimize marketing campaigns, and enhance personalization efforts**. For example, an e-commerce company might use the model to identify high-intent shoppers and offer them exclusive promotions. |
| What problems does this model solve? | The key pain points addressed by the model. | Marketers often struggle with **identifying the right customers to target** and **optimizing engagement efforts**. This model **reduces guesswork** by providing a **data-driven approach** to customer targeting, ensuring that marketing resources are allocated efficiently. |
| What industries or domains are this model relevant for? | A list of applicable industries. | The model is applicable across multiple industries, including **e-commerce, retail, financial services, telecommunications, and media**. Any business that relies on customer engagement and personalized marketing can benefit from this model. |
| How should this model not be used? | Any misuse cases that should be avoided. | The model **should not be used for high-risk decision-making**, such as **financial credit scoring, medical diagnostics, or legal assessments**. Additionally, it is not intended for use in **predicting personally sensitive behaviors** (such as, health conditions, political preferences) due to potential ethical concerns. |

{style="table-layout:auto"}

+++

### Model inputs and outputs {#model-inputs-and-outputs}

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What types of data does the model take as input? | The types of data that the model takes as input, this includes: data features, formats, and sources. | The model processes **customer behavioral data, demographic attributes, and historical interactions**. This includes data such as website visit frequency, past purchase history, engagement with marketing emails, and demographic information. |
| What format should the inputs be in? | The accepted input formats. | Input data must be structured as **JSON objects** containing customer attributes and behavioral signals. For batch processing, the model accepts **CSV files** formatted according to Adobe Experience Platform's data ingestion standards. |
| What does the model output? | The type of output generated by the model. | The model outputs a propensity score between 0 and 1, where higher values indicate a higher likelihood of the predicted event occurring. Additionally, it provides feature importance scores, allowing users to understand which factors influenced the prediction. |
| What are some example inputs and outputs? | A sample input and corresponding output. | <ul><li>**Example Input:** json { "customer_id": 12345, "past_purchases": 3, "last_visit_days": 7, "email_click_rate": 0.4 }</li><li>**Example Output:** json { "customer_id": 12345, "propensity_score": 0.82 }</li></ul> |

{style="table-layout:auto"}

+++

### Training data {#training-data}

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What datasets were used to train the model? | A description of the data sources. | The model was trained on first-party, anonymized customer interaction data collected via Adobe Experience Platform. It includes historical customer behavioral data, transaction records, email interactions, and engagement metrics across multiple industries. |
| What is the size and source of the data? | The volume and origin of the training dataset. | The training dataset consists of 10 million customer records sourced from a diverse set of Adobe Experience Platform customers. These records include historical customer interactions, transactional data, behavioral engagement logs, and demographic information from various industries such as retail, e-commerce, telecommunications, and finance. Data was collected over a 24-month period, ensuring sufficient representation of seasonal trends and long-term engagement patterns. |
| Are there any known biases in the dataset? | Bias considerations and mitigation efforts. | The dataset is predominantly sourced from high-engagement users, which may introduce selection bias. To mitigate this, the model applies stratified sampling, bias auditing techniques, and data augmentation strategies. |
| How is the data preprocessed? | Steps taken to clean and prepare the data. | The dataset undergoes extensive preprocessing to ensure data consistency, quality, and usability. <ol><li>**Handling Missing Values**: Missing values are addressed using a combination of mean imputation (for numerical fields), mode imputation (for categorical fields), and predictive modeling (for complex missing cases).</li><li>**Categorical Encoding:** Categorical variables such as customer segments and purchase categories are converted into numerical representations through one-hot encoding and target encoding techniques.</li><li>**Feature Scaling & Normalization:** Min-max scaling is applied for bounded variables (e.g., age, income), while z-score standardization is used for normally distributed features.</li><li>**Additional Preprocessing:** The pipeline includes outlier detection and removal, duplicate filtering, timestamp standardization, and feature engineering to enhance predictive.</li></ol> |

{style="table-layout:auto"}

+++

### Model architecture and training {#model-architecture-and-training}

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What architecture does the model use? | The type of neural network, ensemble method, etc. | The model leverages Gradient Boosting Decision Trees (GBDT) using XGBoost, optimized for structured data. It is trained on historical customer event sequences to identify predictive behavioral patterns. |
| What algorithms were applied?  | The machine learning techniques that were used. | The model is built using a supervised learning approach, leveraging Gradient Boosting Decision Trees (GBDT) with XGBoost as the primary learning algorithm. Additionally, logistic regression is incorporated as a baseline model for benchmarking predictive accuracy. |
| What training frameworks were used? | The libraries or platforms used for training. | The model was developed using TensorFlow, XGBoost, and scikit-learn. Training runs on Adobe AI cloud infrastructure using NVIDIA V100 GPUs, supporting large-scale datasets. |
| What compute resources were used for training? | The hardware and cloud resources that were used for training. | NVIDIA V100 GPUs, trained on Google Cloud infrastructure. |
| What evaluation methods were used? | The metrics and testing procedures that were used for evaluation. | AUC-ROC, precision-recall, and cross-validation. |

{style="table-layout:auto"}

+++

### Performance and evaluation {#performance-and-evaluation}

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| How was the model tested? | The methods used to validate performance. | The model was tested using a holdout validation approach, where 80% of the data was used for training, and 20% was reserved for evaluation. |
| What evaluation metrics were used? | The key performance indicators. | The model's effectiveness is measured using **AUC-ROC (0.85)**, **precision-recall (0.78)**, and **F1-score (0.80)**. These metrics help assess the model's predictive power across different segments. |
| How does performance vary across different scenarios? | The context-specific performance variations. | Lower accuracy for new customer segments with limited historical data. |
| Are there any known weaknesses or failure cases? | Any limitations or failure points. | The model may underperform for customers with limited historical data (cold-start problem). Additionally, seasonality effects, such as holiday shopping trends, may require frequent retraining to maintain accuracy. |

{style="table-layout:auto"}

+++

### Fairness and bias {#fairness-and-bias}

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What fairness checks were performed? | The bias analysis and mitigation processes that were performed. | The model underwent demographic parity testing and adversarial fairness evaluations to detect performance disparities across different user segments. |
| Does the model disproportionately affect certain groups? | Any disparities in the performance that have been identified. | Analysis revealed a 5% performance drop for users with low historical interaction data. To address this, the model incorporates re-weighting techniques during training. |
| How does the model mitigate bis? | The techniques used to address bias. | The dataset is stratified to ensure proportional representation of different customer demographics, and fairness constraints are introduced during training to prevent the model from favoring any particular group. Regular bias audits are conducted using demographic parity analysis, allowing adjustments if performance disparities are detected. |

{style="table-layout:auto"}

+++

### Explainability and interpretability {#explainability-and-interpretability}

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| Can users understand why the model makes certain decisions? | The interpretability methods used by the model. | The model leverages **SHapley Additive Explanations (SHAP)** to quantify the impact of each input feature on its predictions, providing transparency into how customer attributes influence propensity scores. SHAP values enable both global interpretability, identifying the most influential factors across all predictions, and local interpretability, explaining individual predictions for specific customers. |
| What tools or techniques are available for interpretability? | The available explainability tools. | The model supports **Local Interpretable Model-Agnostic Explanations (LIME)** and SHAP to provide insights into how input features influence predictions. LIME generates local explanations by creating perturbed versions of the input data and observing changes in predictions, while SHAP assigns contribution values to each feature, offering both global and local interpretability of model decisions. |

{style="table-layout:auto"}

+++

### Robustness and generalization {#robustness-and-generalization}

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| How well does the model perform on unseen data? | The findings on generalization performance testing. | The model maintains **80% AUC-ROC** when tested on unseen datasets, demonstrating strong generalization to new customer records. Performance remains stable across different customer segments but shows slight degradation when user behavior significantly deviates from historical patterns. | 
| Has the model been stress-tested for adversarial inputs? | The details from the robustness evaluation. | The model has been evaluated against perturbed and adversarial inputs, including missing data, outlier injection, and intentional mislabeling. While performance remains robust under normal conditions, minor accuracy degradation (approximately 3-5%) was observed under extreme adversarial modifications. |

{style="table-layout:auto"}

+++

### Security and privacy considerations {#security-and-privacy-considerations}

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| Does the model handle sensitive data? | Any information compliance with privacy laws. | The model does not process or retain any personally identifiable information (PII), and all data used for training is anonymized and aggregated. It adheres to strict compliance with GDPR, CCPA, and internal Adobe privacy policies to ensure responsible data usage. |
| What privacy-preserving techniques were used? | The techniques used to ensure privacy measures. | The model incorporates differential privacy techniques to add controlled noise to data, preventing re-identification of individuals. Additionally, hashing, anonymization, and tokenization methods are used to remove PII before model training and inference. |

{style="table-layout:auto"}

+++

### Monitoring and maintenance {#monitoring-and-maintenance}

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| How is model performance monitored over time? | Details on the tracking mechanisms used for the model. | The model is continuously monitored via WatsonX, tracking key performance indicators such as accuracy drift, feature importance shifts, and prediction stability. Anomaly detection and alerting mechanisms notify the team when significant deviations from expected behavior occur. |
| How often is the model retrained? | The frequency of updates on the model. | The model is retrained monthly using updated customer interaction data to ensure continued relevance. Periodic retraining helps mitigate data drift and seasonal fluctuations that could impact predictive accuracy. |

{style="table-layout:auto"}

+++

### Ethical considerations and responsible AI {#ethical-considerations-and-responsible-ai}

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What ethical concerns are associated with this model? | The potential risks that have been identified. | The model could potentially introduce bias in decision-making if not monitored correctly. For example, if certain demographics are overrepresented in the training data, the model might unfairly favor specific customer groups. |
| How does the model align with Responsible AI principles?  | Information on how the model complies with AI ethics guidelines. | Adobe Experience Platform follows Responsible AI guidelines, ensuring that models undergo bias audits, fairness testing, and human oversight before deployment. |

{style="table-layout:auto"}

+++

### Known limitations {#known-limitations}

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What are known limitations of the model? | Any identified performance or use case constraints. | The model may struggle to accurately predict outcomes for newly launched products or customer segments where insufficient historical data is available. Additionally, seasonal variations in customer behavior can cause fluctuations in predictive accuracy if not accounted for during retraining. |
| Under what conditions does the model perform poorly? | Any identified weaknesses regarding the model. | Performance declines when customer history is sparse, such as for first-time buyers or users with minimal engagement data. Additionally, if customer behaviors shift due to external factors like economic downturns or industry trends, the model may require rapid adaptation to maintain accuracy. |

{style="table-layout:auto"}

+++

### Future improvements {#future-improvements}

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What improvements are planned for future iterations? | The roadmap for enhancements. | Future iterations will include transfer learning techniques to improve performance for cold-start users and enhance adaptability to changing customer behaviors. Additionally, real-time data integration will be introduced to improve model responsiveness and accuracy in dynamic marketing environments. |

{style="table-layout:auto"}

+++
