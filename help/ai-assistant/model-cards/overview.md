---
title: Model Cards For AI Model Transparency In Adobe Experience Platform
description: Learn about model cards in Adobe Experience Platform.
hide: true
hidefromtoc: true
exl-id: 74a8ef82-cff9-4a7e-95c8-f915eb664eda
---
# Model cards for AI model transparency in Adobe Experience Platform

An AI model card is the standard format by which AI model transparency is communicated. Model cards provide comprehensive information about the underlying model that a given AI tool is built on. Model cards include information such as an AI tool's purpose, training data, performance metrics, limitations, and ethical considerations. You can use the transparency that model cards provide to better understand the capabilities and limitations of the model, as well as to better promote responsible and fair use of AI.

Model cards are public and are intended to improve both existing and prospective customer understanding of the AI models that Adobe uses. Model cards are generally static. However, there are several aspects of AI models that can change over time, including lineage, bias, and other transparency attributes.

Read this document to learn about model cards in Adobe Experience Platform.

## Model card sections {#model-card-sections}

A model card is composed of a variety of different sections, each focusing on a particular aspect of the AI model.

Read the following for a guide on the different sections of a model card, including information the questions they address.

### Model overview {#model-overview}

The model overview contains general information on an AI model. Use this section to provide information such as the name, purpose, and type of your AI model. Additionally, you can use this section to identify your intended users and elaborate on how your model integrates with Experience Platform.

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What is the name of the model? | The official name and version of the AI model | **CustomerAI Propensity Scoring Model v2.0** <br>CustomerAI is an AI-powered model designed to generate propensity scores for users based on their past behaviors and interactions with a business. It helps predict the likelihood of a customer taking specific actions, such as making a purchase, engaging with content, or churning. This model is deployed within Adobe Experience Platform and integrates with various marketing and customer analytics workflows.</br> |
| What is the purpose of the model? | A brief description of what the model is designed to do. | The model is designed to provide marketers and customer engagement teams with actionable insights by predicting the probability that a customer will perform a given action, such as making a purchase, signing up for a subscription, or engaging with an email campaign. The outputs allow businesses to optimize audience segmentation and personalize customer interactions based on predicted behaviors. |
| What type of model is it? | The type of the model, such as classification, regression, generative, etc. | This is a s**upervised learning classification model** that predicts the probability of an event occurring (e.g., purchase, churn, engagement) given historical customer data. It is trained using gradient boosting decision trees (GBDT) with logistic regression to model propensity scores. |
| Who are the intended users? | The internal and external user groups that the model is intended for. | The primary users of this model are marketing professionals, data analysts, and customer engagement teams who leverage Adobe Experience Platform to drive data-driven marketing strategies. |
| How does this model integrate with Adobe Experience Platform? | The integration details and APIs used, as well as how they fit into the workflows. | CustomerAI integrates directly into **Adobe Experience Platform's AI services**, allowing users to access model outputs through pre-built APIs and dashboards. The propensity scores generated by the model can be used within **Adobe Journey Optimizer**, **and Adobe Real-Time CDP**, to refine audience segmentation and tailor marketing strategies. |

{style="table-layout:auto"}

+++

### Intended use {#intended-use}

The intended use section contains information on your AI model's primary use cases. You can use this section to expand on the problems that your model intends to solve, the industries and/or domains that your model is relevant for, and the misuse cases that should be avoided when using your AI model.

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What are the primary use cases? | The scenarios where the model is expected to be used. | This model is primarily used for **customer segmentation, targeted marketing, and churn prediction**. Businesses leverage this model to **predict customer purchase intent, optimize marketing campaigns, and enhance personalization efforts**. For example, an e-commerce company might use the model to identify high-intent shoppers and offer them exclusive promotions. |
| What problems does this model solve? | The key pain points addressed by the model. | Marketers often struggle with **identifying the right customers to target** and **optimizing engagement efforts**. This model **reduces guesswork** by providing a **data-driven approach** to customer targeting, ensuring that marketing resources are allocated efficiently. |
| What industries or domains are this model relevant for? | A list of applicable industries. | The model is applicable across multiple industries, including **e-commerce, retail, financial services, telecommunications, and media**. Any business that relies on customer engagement and personalized marketing can benefit from this model. |
| How should this model not be used? | Any misuse cases that should be avoided. | The model **should not be used for high-risk decision-making**, such as **financial credit scoring, medical diagnostics, or legal assessments**. Additionally, it is not intended for use in **predicting personally sensitive behaviors** (such as, health conditions, political preferences) due to potential ethical concerns. |

{style="table-layout:auto"}

+++

### Model inputs and outputs {#model-inputs-and-outputs}

The model inputs and outputs section contains information on the supported data types that your model takes as input and returns as output. You can use this section to provide examples of the data inputs and outputs that are relevant to your AI model.

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What types of data does the model take as input? | The types of data that the model takes as input, this includes: data features, formats, and sources. | The model processes **customer behavioral data, demographic attributes, and historical interactions**. This includes data such as website visit frequency, past purchase history, engagement with marketing emails, and demographic information. |
| What format should the inputs be in? | The accepted input formats. | Input data must be structured as **JSON objects** containing customer attributes and behavioral signals. For batch processing, the model accepts **CSV files** formatted according to Adobe Experience Platform's data ingestion standards. |
| What does the model output? | The type of output generated by the model. | The model outputs a propensity score between 0 and 1, where higher values indicate a higher likelihood of the predicted event occurring. Additionally, it provides feature importance scores, allowing users to understand which factors influenced the prediction. |
| What are some example inputs and outputs? | A sample input and corresponding output. | <ul><li>**Example Input:** json { "customer_id": 12345, "past_purchases": 3, "last_visit_days": 7, "email_click_rate": 0.4 }</li><li>**Example Output:** json { "customer_id": 12345, "propensity_score": 0.82 }</li></ul> |

{style="table-layout:auto"}

+++

### Training data {#training-data}

The training data section contains information on the datasets that were used to train a given AI model. You can use this section to elaborate on the size and source of the training data, biases that were identified in the dataset, and how data was preprocessed.

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What datasets were used to train the model? | A description of the data sources. | The model was trained on first-party, anonymized customer interaction data collected via Adobe Experience Platform. It includes historical customer behavioral data, transaction records, email interactions, and engagement metrics across multiple industries. |
| What is the size and source of the data? | The volume and origin of the training dataset. | The training dataset consists of 10 million customer records sourced from a diverse set of Adobe Experience Platform customers. These records include historical customer interactions, transactional data, behavioral engagement logs, and demographic information from various industries such as retail, e-commerce, telecommunications, and finance. Data was collected over a 24-month period, ensuring sufficient representation of seasonal trends and long-term engagement patterns. |
| Are there any known biases in the dataset? | Bias considerations and mitigation efforts. | The dataset is predominantly sourced from high-engagement users, which may introduce selection bias. To mitigate this, the model applies stratified sampling, bias auditing techniques, and data augmentation strategies. |
| How is the data preprocessed? | Steps taken to clean and prepare the data. | The dataset undergoes extensive preprocessing to ensure data consistency, quality, and usability. <ol><li>**Handling Missing Values**: Missing values are addressed using a combination of mean imputation (for numerical fields), mode imputation (for categorical fields), and predictive modeling (for complex missing cases).</li><li>**Categorical Encoding:** Categorical variables such as customer segments and purchase categories are converted into numerical representations through one-hot encoding and target encoding techniques.</li><li>**Feature Scaling & Normalization:** Min-max scaling is applied for bounded variables (e.g., age, income), while z-score standardization is used for normally distributed features.</li><li>**Additional Preprocessing:** The pipeline includes outlier detection and removal, duplicate filtering, timestamp standardization, and feature engineering to enhance predictive.</li></ol> |

{style="table-layout:auto"}

+++

### Model architecture and training {#model-architecture-and-training}

The model architecture and training section describes the blueprint of your AI model. This section refers to the structure and design of the AI model, including details about the type of algorithm and evaluation methods used. You can also use this section to provide information on the training frameworks used, as well as the compute resources that were used in training.

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What architecture does the model use? | The type of neural network, ensemble method, etc. | The model leverages Gradient Boosting Decision Trees (GBDT) using XGBoost, optimized for structured data. It is trained on historical customer event sequences to identify predictive behavioral patterns. |
| What algorithms were applied?  | The machine learning techniques that were used. | The model is built using a supervised learning approach, leveraging Gradient Boosting Decision Trees (GBDT) with XGBoost as the primary learning algorithm. Additionally, logistic regression is incorporated as a baseline model for benchmarking predictive accuracy. |
| What training frameworks were used? | The libraries or platforms used for training. | The model was developed using TensorFlow, XGBoost, and scikit-learn. Training runs on Adobe AI cloud infrastructure using NVIDIA V100 GPUs, supporting large-scale datasets. |
| What compute resources were used for training? | The hardware and cloud resources that were used for training. | NVIDIA V100 GPUs, trained on Google Cloud infrastructure. |
| What evaluation methods were used? | The metrics and testing procedures that were used for evaluation. | AUC-ROC, precision-recall, and cross-validation. |

{style="table-layout:auto"}

+++

### Performance and evaluation {#performance-and-evaluation}

The performance and evaluation section contains information on the metrics and methods used to assess how well the model performs its intended tasks. You can use this section to provide information on the evaluation metrics that were used, as well as identified weaknesses or failure cases.

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| How was the model tested? | The methods used to validate performance. | The model was tested using a holdout validation approach, where 80% of the data was used for training, and 20% was reserved for evaluation. |
| What evaluation metrics were used? | The key performance indicators. | The model's effectiveness is measured using **AUC-ROC (0.85)**, **precision-recall (0.78)**, and **F1-score (0.80)**. These metrics help assess the model's predictive power across different segments. |
| How does performance vary across different scenarios? | The context-specific performance variations. | Lower accuracy for new customer segments with limited historical data. |
| Are there any known weaknesses or failure cases? | Any limitations or failure points. | The model may underperform for customers with limited historical data (cold-start problem). Additionally, seasonality effects, such as holiday shopping trends, may require frequent retraining to maintain accuracy. |

{style="table-layout:auto"}

+++

### Fairness and bias {#fairness-and-bias}

The fairness and bias section contain information on how the AI model performed with regards to fairness and bias metrics. Fairness refers to the model's ability to provide equitable outcomes across different demographic groups and use cases, while bias refers to systematic errors that result in unfair outcomes. Use this section to elaborate on the fairness checks that were performed and to discuss how the model mitigates bias.

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What fairness checks were performed? | The bias analysis and mitigation processes that were performed. | The model underwent demographic parity testing and adversarial fairness evaluations to detect performance disparities across different user segments. |
| Does the model disproportionately affect certain groups? | Any disparities in the performance that have been identified. | Analysis revealed a 5% performance drop for users with low historical interaction data. To address this, the model incorporates re-weighting techniques during training. |
| How does the model mitigate bias? | The techniques used to address bias. | The dataset is stratified to ensure proportional representation of different customer demographics, and fairness constraints are introduced during training to prevent the model from favoring any particular group. Regular bias audits are conducted using demographic parity analysis, allowing adjustments if performance disparities are detected. |

{style="table-layout:auto"}

+++

### Explainability and interpretability {#explainability-and-interpretability}

The explainability and interpretability section contains information on an AI model's ability to provide clear and understandable explanations and the ease with which a human user can understand how input features affect predictions and answers. Use this section to explain how users can better understand why your model makes certain decisions and what tools or techniques are available for interpretability.

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| Can users understand why the model makes certain decisions? | The interpretability methods used by the model. | The model leverages **SHapley Additive Explanations (SHAP)** to quantify the impact of each input feature on its predictions, providing transparency into how customer attributes influence propensity scores. SHAP values enable both global interpretability, identifying the most influential factors across all predictions, and local interpretability, explaining individual predictions for specific customers. |
| What tools or techniques are available for interpretability? | The available explainability tools. | The model supports **Local Interpretable Model-Agnostic Explanations (LIME)** and SHAP to provide insights into how input features influence predictions. LIME generates local explanations by creating perturbed versions of the input data and observing changes in predictions, while SHAP assigns contribution values to each feature, offering both global and local interpretability of model decisions. |

{style="table-layout:auto"}

+++

### Robustness and generalization {#robustness-and-generalization}

The robustness and generalization section contains information on how well your AI model can perform on unseen data. Additionally, you can use this section to elaborate on how your model maintains its performance and accuracy given unexpected or challenging inputs.

>[!TIP]
>
>In AI, "unseen data" refers to data that is different from the data that a given model was trained on.

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| How well does the model perform on unseen data? | The findings on generalization performance testing. | The model maintains **80% AUC-ROC** when tested on unseen datasets, demonstrating strong generalization to new customer records. Performance remains stable across different customer segments but shows slight degradation when user behavior significantly deviates from historical patterns. | 
| Has the model been stress-tested for adversarial inputs? | The details from the robustness evaluation. | The model has been evaluated against perturbed and adversarial inputs, including missing data, outlier injection, and intentional mislabeling. While performance remains robust under normal conditions, minor accuracy degradation (approximately 3-5%) was observed under extreme adversarial modifications. |

{style="table-layout:auto"}

+++

### Security and privacy considerations {#security-and-privacy-considerations}

The security and privacy considerations section contains information on the measures and practices implemented to protect sensitive data and ensure your model's safe use. You can use this section to answer questions on how your model handles sensitive data.

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| Does the model handle sensitive data? | Any information compliance with privacy laws. | The model does not process or retain any personally identifiable information (PII), and all data used for training is anonymized and aggregated. It adheres to strict compliance with GDPR, CCPA, and internal Adobe privacy policies to ensure responsible data usage. |
| What privacy-preserving techniques were used? | The techniques used to ensure privacy measures. | The model incorporates differential privacy techniques to add controlled noise to data, preventing re-identification of individuals. Additionally, hashing, anonymization, and tokenization methods are used to remove PII before model training and inference. |

{style="table-layout:auto"}

+++

### Monitoring and maintenance {#monitoring-and-maintenance}

The monitoring and maintenance section contains information on how your model's performance is monitored over time and how often the model is retrained. You can use this section to provide information on how metrics such as accuracy, precision, recall, and latency are tracked.

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| How is model performance monitored over time? | Details on the tracking mechanisms used for the model. | The model is continuously monitored via WatsonX, tracking key performance indicators such as accuracy drift, feature importance shifts, and prediction stability. Anomaly detection and alerting mechanisms notify the team when significant deviations from expected behavior occur. |
| How often is the model retrained? | The frequency of updates on the model. | The model is retrained monthly using updated customer interaction data to ensure continued relevance. Periodic retraining helps mitigate data drift and seasonal fluctuations that could impact predictive accuracy. |

{style="table-layout:auto"}

+++

### Ethical considerations and responsible AI {#ethical-considerations-and-responsible-ai}

The ethical considerations and responsible AI section contains information on any ethical concerns that are associated with your AI Model. This section also contains how well your model algins with responsible AI principles. Use this section to provide information on the potential ethical impacts of your model's use, including recognizing biases, ensuring fairness, and preventing harm to individuals or groups.

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What ethical concerns are associated with this model? | The potential risks that have been identified. | The model could potentially introduce bias in decision-making if not monitored correctly. For example, if certain demographics are overrepresented in the training data, the model might unfairly favor specific customer groups. |
| How does the model align with Responsible AI principles?  | Information on how the model complies with AI ethics guidelines. | Adobe Experience Platform follows Responsible AI guidelines, ensuring that models undergo bias audits, fairness testing, and human oversight before deployment. |

{style="table-layout:auto"}

+++

### Known limitations {#known-limitations}

The known limitations section contains information on the existing limitations that have identified for your AI model. Use this section to underline the conditions in which your AI model may perform poorly and to outline any limitations that users must be aware of.

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What are known limitations of the model? | Any identified performance or use case constraints. | The model may struggle to accurately predict outcomes for newly launched products or customer segments where insufficient historical data is available. Additionally, seasonal variations in customer behavior can cause fluctuations in predictive accuracy if not accounted for during retraining. |
| Under what conditions does the model perform poorly? | Any identified weaknesses regarding the model. | Performance declines when customer history is sparse, such as for first-time buyers or users with minimal engagement data. Additionally, if customer behaviors shift due to external factors like economic downturns or industry trends, the model may require rapid adaptation to maintain accuracy. |

{style="table-layout:auto"}

+++

### Future improvements {#future-improvements}

The future improvements section contains information on feature updates that are planned for your AI model. Use this section to elaborate on your enhancement roadmap.

+++View questions and example answers

| Question | Information needed | Example answer |
| --- | --- | --- |
| What improvements are planned for future iterations? | The roadmap for enhancements. | Future iterations will include transfer learning techniques to improve performance for cold-start users and enhance adaptability to changing customer behaviors. Additionally, real-time data integration will be introduced to improve model responsiveness and accuracy in dynamic marketing environments. |

{style="table-layout:auto"}

+++
