---
title: Adobe Experience Platform Release Notes June 2019
description: The June 2019 release notes for Adobe Experience Platform.
doc-type: release notes
last-update: June 27, 2019
author: crhoades
exl-id: 835da890-d577-47cb-bd94-cf552243ae9b
---
# Adobe Experience Platform release notes 

**Release date: June 28, 2019**

New features in Adobe Experience Platform:

* [[!DNL Data Science Workspace]](#dsw)
* [[!DNL Decisioning Service]](#decisioning)
* [[!DNL Query Service]](#query)

Updates to existing features:

* [[!DNL Experience Data Model (XDM)]](#xdm)
* [[!DNL Segmentation Service]](#segmentation)

## [!DNL Data Science Workspace] {#dsw}

Adobe Experience Platform [!DNL Data Science Workspace] is a fully managed service within [!DNL Experience Platform] that enables data scientists to seamlessly generate insights from data and content across Adobe solutions and third party systems by building and operationalizing Machine Learning Models. [!DNL Data Science Workspace] is tightly integrated with [!DNL Platform] and powers the end-to-end data science lifecycle, including exploration and preparation of XDM data, followed by the development and operationalization of Models to automatically enrich [!DNL Real-time Customer Profile] with Machine Learning Insights.

**Key features**

| Feature    | Description  |
| -----------| ---------- |
| Provisioning and compute isolation | Provision dedicated compute resources needed to enable data scientists to execute untrusted code within [!DNL Experience Platform] in a secure manner. |
| First-time user experience | Includes out-of-the box samples for various Machine Learning frameworks and languages such as [!DNL Python], R, PySpark and Scala [!DNL Spark].|
| Notebooks| Customized environment for data scientists/data engineers powered by [!DNL Jupyter Notebooks] to enable them to prepare data, extract features, and develop ML Models with a curated list of libraries and popular Machine Learning frameworks. |
| Data exploration | Seamless access to XDM data ingested into [!DNL Platform] integrated with [!DNL Platform Data Access] SDK. |
| Data visualization | Ability to execute SQL queries in [!DNL Jupyter Notebooks] to accelerate data prep and feature engineering.|
| Feature pipelines | API/SDK for Scala/PySpark to deploy feature engineering pipelines for transforming core XDM data into feature schemas. |
| Model authoring | Template and Runtimes that enable data scientists to focus on Model development without having to implement infrastructure code for accessing data and compute resources. You can import model code and operationalize it to derive Insights from data in [!DNL Platform]. |
| Enterprise model management| Support for multi-tenant data model to track model versions and associated hyperparameter configurations to provide foundation for partner ecosystem. |
| Model evaluation | Evaluate and optimize regression and classification models in [!DNL Python], PySpark, R, and Scala.|
| Model deployment | Ability to compare evaluation metrics and configurations across multiple experiment runs and publish the optimal model as a Service.|
| Batch scoring | Enrich [!DNL Real-time Customer Profile] with Machine Learning insights or write them as datasets back to [!DNL Platform]|
| Scheduling | Integrated with [!DNL Platform] Orchestration Service to automate Model training, scoring, and feature pipelines with user-defined schedules through APIs. |

**Known issues**

* Scheduling and feature pipelines are currently available via API only, with a UI to be added in a future release.

For more information, visit the [Data Science Workspace Overview](../../data-science-workspace/home.md).

## [!DNL Decisioning Service] {#decisioning}

Adobe Experience Platform [!DNL Decisioning Service] provides the ability to programmatically and intelligently select the ‘Next Best Experience’ from a set of available options for a given individual, deliver them to any channel or application, and perform reporting and analysis.

A prebuilt rich data model enables the use case of "Next Best Offer" decisioning in a channel agnostic way.

**Key features**

| Feature    | Description  |
| -----------| ---------- |
| Business object repository  | A repository driven by JSON schema models allows a developer to create, read, update and delete a variety of business objects. The repository provides general purpose, expressive query APIs as well as schema aware search.|
| Repository containers | Within the business object repository a developer may isolate their concerns around projects, business or organizational units, or around life cycle stages of a project (for example, in development and integration, staging, or for live production use). Those isolations are called repository containers.|
| Roles and permissions | Using the [!DNL Admin Console], an organization can create and manage profiles to grant targeted access to resources by type, access operation, and container. Users can be added to those access profiles and effective access privileges are automatically computed from those policies. |
| Prebuilt offer object model | Without the need to first build a data model, a [!DNL Platform] developer can leverage prebuilt JSON schemas and relationships to create an offer catalog, define decision rules and constraints, and assemble offer collections for decisioning. |
| Decision rules based on profile and non-profile data | A tight integration with the [!DNL Real-time Customer Profile] allows a developer to create decision rules that leverage Profile data. Not only can decisions be made using profile attributes but also based on the experience event history of a profile and based on business entities unrelated to a user identity (e.g. traffic conditions, product inventory). Any [!DNL Experience Data Model] (XDM) entity for which a schema exists in the [!DNL Schema Registry] can be used for the decision rules. Rules are first class entities and can be reused for any of the decision options and activities. |
| Ranking and capping | Decision options that fulfill all eligibility and other constraints for a given user are ranked and the best option is selected. Additional per user and global capping constraints can be used to limit the exposure of the available options, thus enabling personalization with resource constraints and user fatigue in mind. |
| [!DNL Decisioning] REST APIs | The [!DNL Decisioning Service] can be invoked using a simple REST API to get the Next Best Offer for a given individual. A metrics API can be used to check real-time offer proposition and capping values. |
| Streaming Decision Events into [!DNL Data Lake] and [!DNL Query Service] | The [!DNL Decisioning Service] auto-creates datasets to stream all XDM Decision Events automatically into the [!DNL Data Lake]. The datasets are then available for analysis and reporting using [!DNL Query Service]. |
| Developer enablement | Self service opt-in with documentation on Adobe I/O including tutorials for various topics. |

**Known issues**

* The offer data model is not exposed through the [!DNL Schema Registry] and can therefore only be extended in limited ways. The model schema has built-in structures to allow the attachment of custom data. In the future, you will be able to extend a base XDM model class to define your own custom decisioning domains.
* You must be provisioned with the Offer Management domain model and users and integrations must be managed in this product context.

## [!DNL Query Service] {#query}

[!DNL Query Service] provides the ability to use standard SQL to query data in Adobe Experience Platform to support many different analysis and data management use cases. It is a serverless tool which allows you to join any datasets in the [!DNL Data Lake] and capture the query results as a new dataset for use in reporting, [!DNL Data Science Workspace], or for ingestion into [!DNL Profile Service].

You can use [!DNL Query Service] to build data analysis ecosystems, creating a picture of consumers across their various interaction channels. These channels might include:

* Point-of-sale system
* Web
* Mobile
* CRM system

**Key features**

| Feature    | Description  |
| -----------| ---------- |
| Query editor | Use a web-based tool to write, validate, test, and execute queries. It includes a console for detailed information on the execution of queries, as well as the ability to preview query results. | 
| Dataset creation | Create datasets on [!DNL Experience Platform] via standard SQL syntax. |
| Adobe-defined functions | Leverage shortcut functions for common tasks like identifying sessions or setting attribution. |
| BI tool connectivity | Use the PostgreSQL (Postgres) drivers found in common BI tools to connect to [!DNL Query Service] to create reports and visualizations. Supported tools include: [!DNL Tableau], [!DNL Power BI], and [!DNL Looker]. Find authentication information on the Credentials tab. |
| Database management tool connectivity | Connect [!DNL Aqua Data Studio] or [!DNL DB Visualizer] to [!DNL Query Service] for data exploration and dataset creation functionality. [!DNL Query Service] also supports connectivity from R Studio. Find authentication information on the Credentials tab. |
| Command line query tool | Connect PSQL to be able to run queries from the command line. |
| Query Log  | Keeps a history of queries executed by [!DNL Query Service] and enables you to find prior SQL for editing, execution, or for creating a dataset out of the results. |
| Query scheduling API  | Schedule queries for recurring execution via this API. |

**Known issues**

* [!DNL Query Editor] shows a sample of 100 rows of the results for your queries. In order to persist the complete result set, use the dataset creation capabilities from the Query Log. 
* Near-term releases will add support for Views and a UI for applying schedules to queries. 

For more information about [!DNL Query Service], see the [product documentation](../../query-service/home.md).

## [!DNL Experience Data Model] (XDM) {#xdm}

Standardization and interoperability are key concepts behind [!DNL Experience Platform]. [!DNL Experience Data Model] (XDM), driven by Adobe, is an effort to standardize customer experience data and define schemas for customer experience management.

XDM is a publicly documented specification designed to improve the power of digital experiences. It provides common structures and definitions for any application to communicate with services on Adobe Experience Platform. By adhering to XDM standards, all customer experience data can be incorporated into a common representation delivering insights in a faster, more integrated way. You can gain valuable insights from customer actions, define customer audiences through segments, and use customer attributes for personalization purposes.

XDM is the mechanism that allows [!DNL Experience Cloud], powered by Adobe Experience Platform, to deliver the right message to the right person, on the right channel, at exactly the right moment.

The methodology on which [!DNL Experience Platform] is built, [!DNL XDM System] operationalizes [!DNL Experience Data Model] schemas for use by [!DNL Experience Platform] components.

**New features**

| Feature    | Description  |
| ---------- | ------------ |
| JSON Schema constraints  | The following datatypes now have additional options in the user interface to define constraints: `string` - min/max length, pattern, default value, formats (as defined in [JSON Schema draft-6](https://tools.ietf.org/html/draft-wright-json-schema-01)) and `double` - min/max, default value. |
| Custom `$id`  | You can now provide your own `$id` value when creating resources in POST requests. |
| Schema Registry performance improvements  | Optimized union schema generation, and enhanced schema caching to greatly improve API response times. |

**Bug Fixes**

* Moved the identityMap field out of context/profile and into its own schema field group to make defining identities more intuitive.
* Patched all existing schemas based on context/profile with context/identitymap.
* Fixed error message when no version is supplied.
* Fixed bug where [!DNL Schema Registry] was giving random responses for profile union schema calls.
* Fixed bug where union schemas were not displaying the correct fields in [!DNL Schema Registry].
* Fixed bug where identity descriptors were occasionally not able to be created with valid namespaces.
* Fixed dereference issue if an object uses `properties` instead of `allOf`.

**Known issues**

* Cannot extend a [!DNL Platform]-supplied field group by adding a field.
* Descriptors are not deleted when a field group is removed from the schema composition.
* Unable to create an enum field with no labels.

To learn more about working with XDM using the [!DNL Schema Registry] API and [!DNL Schema Editor], please read the [XDM System documentation](../../xdm/home.md).

## [!DNL Segmentation Service] {#segmentation}

[!DNL Segmentation Service] defines a particular subset of profiles from your profile store, describing the criteria to distinguish a marketable group of people within your profile store. Segments can be based on record data (such as demographic information) or time series events representing customer touch points with your brand.

For example, in an email campaign focused on running shoes, you could use an audience segment of all users who searched for running shoes within the last 30 days, but did not complete a purchase. Another example could be using a segment to target site content so that it displays only to visitors who belong to a certain tier of your rewards program.

**New features**

| Feature    | Description  |
| -----------| ---------- |
| Relative time rules |You can now choose rolling time windows such as 14 days ago, 3 to 5 hours ago, etc.|
|XDM field summaries |For Attributes on the left-rail, summaries are now available providing a view into your underlying data.|
|Left-rail search |Improved search capabilities for the segments portion of the left rail.|
|eVar friendly names |Improved support for friendly names, allowing you to see more easily what information is captured within custom events and dimensions from Adobe Analytics.|
|Merge policy support |You can now choose which merge policy to apply to their segment definition using a simple dropdown.|

**Bug Fixes**

* Fixed an intermittent issue causing slow loading of the attributes and events building blocks in the left-rail.
* Fixed a bug which caused the estimator to return “NaN” response.
* Fixed an error where some fields were opening the incorrect rule building canvas.

**Known issues**

* None.

For more information, see the [Segmentation Service overview](../../segmentation/home.md).
