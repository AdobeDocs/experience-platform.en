---
keywords: Experience Platform;home;popular topics;Apache Spark;apache spark;Azure HDInsights;azure hdinsights
solution: Experience Platform
title: Apache Spark on Azure HDInsights Source Connector Overview
description: Learn how to connect Apache Spark on Azure HDInsights to Adobe Experience Platform using APIs or the user interface.
exl-id: c4a2a14e-5e16-44b7-b3f1-a98b7229f69e
---
# (Beta) [!DNL Apache Spark] on [!DNL Azure HDInsights] connector

>[!NOTE]
>
>The [!DNL Apache Spark] on [!DNL Azure HDInsights] connector is in beta. See the [Sources overview](../../home.md#terms-and-conditions) for more information on using beta-labeled connectors.

Adobe Experience Platform allows data to be ingested from external sources while providing you with the ability to structure, label, and enhance incoming data using [!DNL Platform] services. You can ingest data from a variety of sources such as Adobe applications, cloud-based storage, databases, and many others.

[!DNL Experience Platform] provides support for ingesting data from a third-party database. [!DNL Platform] can connect to different types of databases such as relational, NoSQL, or data warehouses. Support for database providers include [!DNL Apache Spark] on [!DNL Azure HDInsights].

## IP address allow list

A list of IP addresses must be added to an allow list prior to working with source connectors. Failing to add your region-specific IP addresses to your allow list may lead to errors or non-performance when using sources. See the [IP address allow list](../../ip-address-allow-list.md) page for more information.

The documentation below provides information on how to connect [!DNL Apache Spark] on [!DNL Azure HDInsights] to [!DNL Platform] using APIs or the user interface:

## Connect [!DNL Apache Spark] on [!DNL Azure HDInsights] to [!DNL Platform] using APIs

- [Create an Apache Spark on Azure HDInsights base connection using the Flow Service API](../../tutorials/api/create/databases/spark.md)
- [Explore data tables using the Flow Service API](../../tutorials/api/explore/tabular.md)
- [Create a dataflow for a database source using the Flow Service API](../../tutorials/api/collect/database-nosql.md)

## Connect [!DNL Apache Spark] on [!DNL Azure HDInsights] to [!DNL Platform] using the UI

- [Create a Apache Spark on Azure HDInsights source connection in the UI](../../tutorials/ui/create/databases/spark.md)
- [Create a dataflow for a database source connection in the UI](../../tutorials/ui/dataflow/databases.md)
